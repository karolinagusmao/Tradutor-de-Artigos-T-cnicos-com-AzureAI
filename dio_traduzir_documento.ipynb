{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtaNgkcJXD-C",
        "outputId": "8864de54-6ff1-484a-8a44-a24d32f7b058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.17)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (0.1.142)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain-openai) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain-openai) (1.0.0)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.2.8 python-docx-1.1.2 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install requests python-docx beautifulsoup4 openai langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for script_or_style in soup([\"script\", \"style\"]):\n",
        "         script_or_style.decompose()\n",
        "        texto = soup.get_text(separator = ' ')\n",
        "        #Limpar texto\n",
        "        linhas = (line.strip() for line in texto.splitlines())\n",
        "        parts  = (phrase.strip() for line in linhas for phrase in line.split(\"  \"))\n",
        "        texto_limpo  = '\\n'.join(part for part in parts if part)\n",
        "        return texto_limpo\n",
        "\n",
        "    else:\n",
        "        print(f\"Erro ao acessar a URL. Status code:{response.status_code}\")\n",
        "        return None\n",
        "    text = soup.get_text()\n",
        "    return text\n",
        "\n",
        "extract_text_from_url(\"https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "y09K4ir0XY0j",
        "outputId": "1a85691e-9633-490e-be95-f67e8084ff02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Azure Open AI in VNet - DEV Community\\nSkip to content\\nNavigation menu\\nSearch\\nPowered by\\nSearch\\nAlgolia\\nSearch\\nLog in\\nCreate account\\nDEV Community\\nClose\\nAdd reaction\\nLike\\nUnicorn\\nExploding Head\\nRaised Hands\\nFire\\nJump to Comments\\nSave\\nMore...\\nCopy link\\nCopy link\\nCopied to Clipboard\\nShare to X\\nShare to LinkedIn\\nShare to Facebook\\nShare to Mastodon\\nReport Abuse\\nKenichiro Nakamura\\nPosted on\\nOct 12, 2023\\nAzure Open AI in VNet\\n# azure\\n# openai\\n# security\\nGPT models are hosted in multiple service vendor at the moment, and Microsoft Azure is one of them.\\nEven though the models themselves are the same, there are many differences including:\\ncost\\nfunctionalities\\ntype of models and versions\\ngeo location\\nsecurity\\nsupport\\netc.\\nOne of the most important aspects when we use it in an Enterprise Environment is, of course, security.\\nBy using Azure network security features with Azure Open AI, customers can consume the Open AI service from and within the VNet, therefore no information is flowing in public.\\nSample Deployment\\nAzure Sample repo provides a sample bicep files to deploy Azure Open AI into VNet environment.\\nGitHub: openai-enterprise-iac\\nThe key features the bicep uses are:\\nVNet\\nVNet integration for Web App\\nPrivate Endpoint for Azure Open AI\\nPrivate Endpoint for Cognitive Search\\nPrivate DNS Zone\\nBy using these features, all the outbound traffic from the Web App only routed inside the VNet and all the names are resolved into private IP addresses. Open AI and Cognitive Search shut down the public IP address, thus there is not public interface endpoint available anymore.\\nDeploy\\nThe bicep file will deploy following Azure Resources.\\nLet\\'s deploy and confirm how it works. I create a resource group in East US region for my own test.\\ngit clone https://github.com/Azure-Samples/openai-enterprise-iac\\ncd\\nopenai-enterprise-iac\\naz group create\\n-n\\nopenaitest\\n-l\\neastus\\naz deployment group create\\n-g\\nopenaitest\\n-f\\n. \\\\i nfra \\\\m ain.bicep\\nEnter fullscreen mode\\nExit fullscreen mode\\nOnce I run the commend above, I see the deployment started.\\nWait until the deployment completes.\\nTest\\nLet\\'s see if the deployment was succeeded.\\nAzure Open AI\\nLet\\'s try public access first.\\nI could create a deployment without any issue. But when I try from the Chat playground in my Azure Portal, I see the following error.\\nHow about access via the Web API?\\nFrom an advanced tool of the App Service, I login to Bash session, and first I ping the service URL.\\nI see the private IP address assigned to the Private Endpoint is returend.\\nThen I use curl command to send request to the endpoint.\\nTop comments\\n(0)\\nSubscribe\\nPersonal\\nTrusted User\\nCreate template\\nTemplates let you quickly answer FAQs or store snippets for re-use.\\nSubmit\\nPreview\\nDismiss\\nCode of Conduct\\n•\\nReport abuse\\nAre you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment\\'s\\npermalink .\\nHide child comments as well\\nConfirm\\nFor further actions, you may consider blocking this person and/or\\nreporting abuse\\nRead next\\nUnderstanding \"working-directory\" in GitHub Actions\\nCiCube -\\nNov 2\\nHow to remove null or empty string values from a list in Terraform\\nMark Wragg -\\nOct 22\\nIssue 67 of AWS Cloud Security Weekly\\nAJ -\\nOct 22\\nThe Rise of Virtual Influencers Powered by AI\\nMohit Sharma -\\nSep 29\\nKenichiro Nakamura\\nFollow\\nJoined\\nFeb 3, 2018\\nMore from\\nKenichiro Nakamura\\nAzure ML Prompt flow: Use content safety before sending a request to LLM\\n# azure\\n# promptflow\\n# contentsafety\\nDon\\'t waste time to write README, use readme-ai instead\\n# ai\\n# readme\\n# openai\\nC#: Azure Open AI and Function Calling\\n# azure\\n# openai\\n# functioncalling\\nThank you to our Diamond Sponsor\\nNeon\\nfor supporting our community.\\nDEV Community\\n— A constructive and inclusive social network for software developers. With you every step of your journey.\\nHome\\nDEV++\\nPodcasts\\nVideos\\nTags\\nDEV Help\\nForem Shop\\nAdvertise on DEV\\nDEV Challenges\\nDEV Showcase\\nAbout\\nContact\\nFree Postgres Database\\nGuides\\nSoftware comparisons\\nCode of Conduct\\nPrivacy Policy\\nTerms of use\\nBuilt on\\nForem\\n— the\\nopen source\\nsoftware that powers\\nDEV\\nand other inclusive communities.\\nMade with love and\\nRuby on Rails . DEV Community\\n©\\n2016 - 2024.\\nWe\\'re a place where coders share, stay up-to-date and grow their careers.\\nLog in\\nCreate account'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
        "\n",
        "client = AzureChatOpenAI(\n",
        "    azure_endpoint = \"https://13981-m3m4gw4p-westeurope.openai.azure.com/\",\n",
        "    api_key = \"5yfjDPv78gKQwVQy3Z4MGlJ0etZKG2LiFtB8znmc6k7aj13PsCxQJQQJ99AKAC5RqLJXJ3w3AAAAACOGbjEV\",\n",
        "    api_version = \"2024-02-15-preview\",\n",
        "    deployment_name = \"gpt-4o-mini\",\n",
        "    max_retries = \"0\"\n",
        ")\n",
        "\n",
        "def translate_article(text,lang):\n",
        "  messages = [\n",
        "      (\"system\", \"Voce atua como tradutor de textos\"),\n",
        "      (\"user\", f\"Traduza o {text} para o idimoa {lang} e responda em markdown\")\n",
        "  ]\n",
        "\n",
        "  response = client.invoke(messages)\n",
        "  print(response.content)\n",
        "  return response.content\n",
        "\n",
        "translate_article(\"let's see if the deployment was succeeded.\",\"pt-br\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "o64aOkK_ZAVT",
        "outputId": "d6accfeb-bdd5-4a0c-c282-4f887fa62a9d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vamos ver se a implantação foi bem-sucedida.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Vamos ver se a implantação foi bem-sucedida.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Como o link do curso ultrapassava o limite de tokens, eu troquei por uma página mais simples\n",
        "url ='https://isadorapassos.github.io/'\n",
        "text = extract_text_from_url(url)\n",
        "#Também alterei a tradução para inglês, já que a página está em portugês\n",
        "article = translate_article(text, \"en\")\n",
        "\n",
        "print(article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41dDhB83oTp0",
        "outputId": "47f11287-69aa-480c-9132-c320d09afbcd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Personal Website\n",
            "## Isadora Barroso Passos\n",
            "\n",
            "### About Me:\n",
            "I am a fourth-semester student in the Information Systems course. This page was created to organize the activities carried out during the Web Fundamentals class.\n",
            "\n",
            "### Activities:\n",
            "- Exercises from the Web Fundamentals Class\n",
            "- Exercises from the One Month Course for the language (English)\n",
            "# Personal Website\n",
            "## Isadora Barroso Passos\n",
            "\n",
            "### About Me:\n",
            "I am a fourth-semester student in the Information Systems course. This page was created to organize the activities carried out during the Web Fundamentals class.\n",
            "\n",
            "### Activities:\n",
            "- Exercises from the Web Fundamentals Class\n",
            "- Exercises from the One Month Course for the language (English)\n"
          ]
        }
      ]
    }
  ]
}